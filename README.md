# Курсовой проект по курсу highload в технопарке

## 1. **Выбор темы**
Сервис по планированию путешествий (TripAdvisor)

## 2. **Определение возможного диапазона нагрузок подобного проекта**
### TripAdvisor
Месячная аудитория- 490 миллионов [Источник](https://review42.com/tripadvisor-statistics/)
Среднее время проведения на подобных сайтах- 3 минуты [Источник](https://www.similarweb.com/website/tripadvisor.com/)

## 3. **Выбор планируемой нагрузки**
Планируемая нагрузка - 50% от доли TripAdvisor, т.е
- Месячная аудитория:  
    ```490/2=245 миллиона человек в месяц```

Учитывая специфику сайта (пользователи редко возвращаются на сайт в течение одного месяца, так как выбор путешествия скорее всего дело одного захода), можем принять число ежедневно активных юзеров=245 млн/30=8.1 млн человек
    
Оценивая себя как среднестатистического пользователя, подсчитал сколько пользовательского трафика займет стандартный workflow пользователя, а именно скролл ленты:
За 1 минуту 40 секунд было израсходовано 21 Мб траффика, 
![alt-текст](https://github.com/EvilBorsch/booking-highload/blob/main/Скриншоты%20(2).png "lenta")

Большая часть ajax запросов идут в рекламные сервисы и в сервисы аналитики, число запросов = 16, а объем передаваемых данных = 0.23 мб
Собственно основной объем трафика приходится на статику

За 1 минуту 40 секунд минут пользования сайтом, На динамику пришлось 0.23 мб трафика и 16 запросов. На статику 9.5+0.3+3.7=13,5 мб и 414+142+386=942 запроса.

За сутки пользования сервисом в среднем пользователем будет израсходованно
Для динамики: 

- ```0.23 * (3/1,4)=0.64 мб трафика``` 
- ```16 * (3/1.4)=34 запроса ```
Для статики: 
- ```13,5* (3/1,4)=28.9 мб трафика``` 
- ```556 * (3/1.4)=2018 запросов ```

Расчитаем средний трафик для динамики и статики:
- Динамика: (0.64 мб * 8 100 000) / (24 * 60 * 60) = 60 Гб/с
- Статика: (28.9 мб * 8 100 000) / (24 * 60 * 60) = 2697 ГБ/c 

Расчитаем средний RPS для динамики и статики:
- Динамика: (34 * 8 100 000) / (24 * 60 * 60) = 3 187 RPS
- Статика: (2018 * 8 100 000) / (24 * 60 * 60) =  189 187 RPS

## 4. **Логическая схема базы данных**
![alt-текст](https://github.com/EvilBorsch/booking-highload/blob/main/Снимок%20экрана%202020-10-21%20в%2016.38.54.png "Схема бд")

## 5. **Физическая системы хранения**

Данные о пользователе, отелях и отзывы имеют для нас наибольший приоритет, потому что без них наше приложение потеряет ключевой функционал. Для хранения этих данных я выбрал PostgreSQL, как наиболее функциональную и надежную реляционную базу данных.

Активные сессии пользователя будем хранить в redis. Redis имеет встроенный API для работы с Memcached, что позволяет использовать эффективное кэширование данных. А так же неблокирующую master-slave репликацию.

## 6. **Выбор прочих технологий**

#### Backend
Golang. Перспективный язык программирования, со статической типизацией, эффективной многопоточностью, использующий аналог корутин(горутины), а так же удобным менеджером зависимостей (gomod).

#### Frontend
CSS, HTML , TypeScript - как стандарт Frontend разработки.
Webpack — Это сборщик модулей JavaScript с открытым исходным кодом он принимает модули с зависимостями и генерирует статические ресурсы, представляющие эти модули.
Sass - метаязык на основе CSS, предназначенный для увеличения уровня абстракции CSS-кода и упрощения файлов каскадных таблиц стилей.
React - обеспечивающий модульность, быстрый рендеринг, высокую run-time производительность.

#### Протоколы взаимодействия
Протокол связи между фронтендом и бэкендом - https, данные будут передаваться в формате json.
Общение между микросервисами на бэкенде будет осуществляться по протоколу gRPC, данные будут передаваться в формате protobuf

#### Обеспечение качества
Как на фронтенде, так и на бэкенде будут использованы статические и динамические анализаторы кода, интеграционные и юнит тесты. Их запуск будет автоматизирован в Gitlab CI.

#### Протоколы взаимодействия

Протокол связи между фронтендом и бэкендом - https, данные будут передаваться в формате json. 

Общение между микросервисами на бэкенде будет осуществляться по протоколу gRPC, данные будут передаваться в формате protobuf.

## 7. **Расчет нагрузки и потребного оборудования**

##### Активные сессии

Для хранения всех сессий пользователей(245 млн) согласно [статье](https://medium.com/@lucasmagnum/redistip-estimate-the-memory-usage-for-repeated-keys-in-redis-2dc3f163fdab) нам примерно потребуется: 245 000 000 * 220 = 54 00 000 000 байт = 54 Гб

##### Пользователи

Одна запись пользователя в таблице занимает примерно (4+30+30+30+30) 124 байта. Тогда общий объем занимаемой памяти составит 245 млн *124 б= 30 Гб.

##### Отзывы

Одна запись комментария в таблице занимает примерно (4+4+4+200+4+8+4+4) 232 байта. Согласно статье [Статистика](https://expandedramblings.com/index.php/tripadvisor-statistics/) Число отзывов= 870 миллионов => Общий объем памяти = 870млн * 232 = 201 Гб

##### Фото

В среднем одна фотография весит около 500 кб. 
Если считать что у каждого пользователя есть аватарка, и к каждому отелю приложено в среднем 5 фото. 
Объем информации: 
245 млн* 0,5 Мб + 1,2 млн (число отелей [Статистика](https://expandedramblings.com/index.php/tripadvisor-statistics/) ) *0,5 Мб= 123 000 Гб
##### Расчет оборудования

Исходя из приведенных выше данных нам потребуется 123,3 тб. для хранения всей нужной информации. При закупке машин со следующими характеристиками:
Будем использовать стойки под 12 SSD дисков для хранилища.

| CPU  (cores)  |      RAM (gb)    |  SSD (gb) |
|:----------:|:-------------:|:------:|
| 32 |  64 | 24 |

На один бекенд сервис приходится нагрузка в 5000rps, значит для нашей системы потребуется:
- ```106875/5000RPS= 21.3 машины```, возьмем с запасом 22
Хранилище:
- ```123,3 Тб/24=6 машин```     
Так что нам потребуется 6 машин под хранилища, 22 под микросервисы на бэкенде и 3 для фронтенда.

## 8. **Выбор хостинга / облачного провайдера и расположения серверов**
Мы будем использловать свои дата центры, так как цены на облачные решения слишком велики для больших сервисов. Клиенты обращаются к нам в основном с территории Европы и США (для китайского и азиатского рынка создаются отдельные продукты, такие как daodao.com) расположим один дата центр в США(Нью-Йорк), а другой в Европе(Франфуркт), по 23 машины в каждом. 

## 9. **Схема балансировки нагрузки (входящего трафика и внутрипроектного, терминация SSL)**
Будем использовать nginx для балансировки нагрузки с использованием схемы L7. Это позволит равномерно распределить нагрузку и решит проблемы медленных клиентов. Также nginx имеет внутренние инструменты для настройки SSL терминации.

## 10. **Обеспечение отказоустойчивости**
Отказоустойчивость обеспечивается несколкими компонентами:
1) Микросервисная архитектура с поднятыми несколькими экземплярами каждого сервиса
2) Несколько балансировщиков нагрузки, позволяющих в случае падения одного из них, перекинуть запросы на другие.
3) Использоваине технологии RAID 10 для хранения данных пользователей и медиа информации, допустимое количество вышедших из строя дисков от 1 до N/2 дисков. Информация не потеряется, если выйдут из строя диски в пределах разных зеркал.
4) Мониторинг метрик, с автоматическим оповещением сотрудников в случае нештатных ситуаций.
