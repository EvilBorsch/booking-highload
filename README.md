# Курсовой проект по курсу highload в технопарке

## 1. **Выбор темы**
Сервис по планированию путешествий (TripAdvisor)

## 2. **Определение возможного диапазона нагрузок подобного проекта**
### TripAdvisor
Месячная аудитория- 490 миллионов [Источник](https://review42.com/tripadvisor-statistics/)
Среднее время проведения на подобных сайтах- 3 минуты [Источник](https://www.similarweb.com/website/tripadvisor.com/)

## 3. **Выбор планируемой нагрузки**
Планируемая нагрузка - 50% от доли TripAdvisor, т.е
- Месячная аудитория:  
    ```490/2=245 миллиона человек в месяц```

Учитывая специфику сайта (пользователи редко возвращаются на сайт в течение одного месяца, так как выбор путешествия скорее всего дело одного захода), можем принять число ежедневно активных юзеров=245 млн/30=8.1 млн человек
    
В среднем за минуту на TripAdvisor отправляется 270 запросов от пользователей [Источник](https://review42.com/tripadvisor-statistics/) (без учета картинок)
Что вполне совпадает с экспериментом:
Оценивая себя как среднестатистического пользователя, подсчитал сколько пользовательского трафика займет стандартный workflow пользователя, а именно скролл ленты:
За 1 минуту 40 секунд было израсходовано 21 Мб траффика, 
![alt-текст](https://github.com/EvilBorsch/booking-highload/blob/main/Скриншоты%20(2).png "lenta")

За 1 минуту 40 секунд минут пользования сайтом, На динамику пришлось 2.3+3.7=6мб трафика и 157+386=543 запроса. На статику 9.5+0.3=10мб и 414+142=556 запросов.

За сутки пользования сервисом в среднем пользователем будет израсходованно
Для динамики:
- ```6* (3/1,4)=12.8 мб трафика``` 
- ```543 * (3/1.4)=1140 запросов ``
Для статики:
- ```10* (3/1,4)=2.1 мб трафика``` 
- ```556 * (3/1.4)=1167 запросов ``

Расчитаем средний трафик для динамики и статики:
- Динамика: (12.8мб * 8 100 000) / (24 * 60 * 60) = 1200 Гб/с
- Статика: (2.1мб * 8 100 000) / (24 * 60 * 60) = 196ГБ/c
Расчитаем средний RPS для динамики и статики:
- Динамика: (1140 * 8 100 000) / (24 * 60 * 60) = 106 875 RPS
- Статика: (2400 * 8 100 000) / (24 * 60 * 60) =  225 000 RPS

## 4. **Логическая схема базы данных**
![alt-текст](https://github.com/EvilBorsch/booking-highload/blob/main/Снимок%20экрана%202020-10-21%20в%2016.38.54.png "Схема бд")

## 5. **Физическая системы хранения**

Данные о пользователе, отелях и отзывы имеют для нас наибольший приоритет, потому что без них наше приложение потеряет ключевой функционал. Для хранения этих данных я выбрал PostgreSQL, как наиболее функциональную и надежную реляционную базу данных.

Активные сессии пользователя будем хранить в redis. Redis имеет встроенный API для работы с Memcached, что позволяет использовать эффективное кэширование данных. А так же неблокирующую master-slave репликацию.

Для повышения отказоустойчивости нашего приложения будем хранить пользователе, отелях и отзывы на разных шардах, что сделает компоненты нашей системы независимыми и выход из стоя одной компоненты не приведет к полной деградации всего сервиса.

## 6. **Выбор прочих технологий**

#### Backend
Golang. Перспективный язык программирования, со статической типизацией, эффективной многопоточностью, использующий аналог корутин(горутины), а так же удобным менеджером зависимостей (gomod).

#### Frontend
CSS, HTML , TypeScript - как стандарт Frontend разработки.
Webpack — Это сборщик модулей JavaScript с открытым исходным кодом он принимает модули с зависимостями и генерирует статические ресурсы, представляющие эти модули.
Sass - метаязык на основе CSS, предназначенный для увеличения уровня абстракции CSS-кода и упрощения файлов каскадных таблиц стилей.
React - обеспечивающий модульность, быстрый рендеринг, высокую run-time производительность.

#### Протоколы взаимодействия
Протокол связи между фронтендом и бэкендом - https, данные будут передаваться в формате json.
Общение между микросервисами на бэкенде будет осуществляться по протоколу gRPC, данные будут передаваться в формате protobuf

#### Обеспечение качества
Как на фронтенде, так и на бэкенде будут использованы статические и динамические анализаторы кода, интеграционные и юнит тесты. Их запуск будет автоматизирован в Gitlab CI.

#### Протоколы взаимодействия

Протокол связи между фронтендом и бэкендом - https, данные будут передаваться в формате json. 

Общение между микросервисами на бэкенде будет осуществляться по протоколу gRPC, данные будут передаваться в формате protobuf.

## 7. **Расчет нагрузки и потребного оборудования**

##### Активные сессии

Для хранения всех сессий пользователей(245 млн) согласно [статье](https://medium.com/@lucasmagnum/redistip-estimate-the-memory-usage-for-repeated-keys-in-redis-2dc3f163fdab) нам примерно потребуется: 245 000 000 * 220 = 54 00 000 000 байт = 54 Гб

##### Пользователи

Одна запись пользователя в таблице занимает примерно (4+30+30+30+30) 124 байта. Тогда общий объем занимаемой памяти составит 245 млн *124 б= 30 Гб.

##### Отзывы

Одна запись комментария в таблице занимает примерно (4+4+4+200+4+8+4+4) 232 байта. Согласно статье [Статистика](https://expandedramblings.com/index.php/tripadvisor-statistics/) Число отзывов= 870 миллионов => Общий объем памяти = 870млн * 232 = 201 Гб

##### Фото

В среднем одна фотография весит около 500 кб. 
Если считать что у каждого пользователя есть аватарка, и к каждому отелю приложено в среднем 5 фото. 
Объем информации: 
245 млн* 0,5 Мб + 1,2 млн (число отелей [Статистика](https://expandedramblings.com/index.php/tripadvisor-statistics/) ) *0,5 Мб= 123 000 Гб
##### Расчет оборудования

Исходя из приведенных выше данных нам потребуется 123,3 тб. для хранения всей нужной информации. При закупке машин со следующими характеристиками:

| CPU  (cores)  |      RAM (gb)    |  SSD (gb) |
|:----------:|:-------------:|:------:|
| 32 |  64 | 4096 |

Так как запросы в основном подразумевают запросы от бэкенда к базам данных, то будем считать, что на бэкенд сервера приходится приблизительно такая же нагрузка, как и на базы данных - 5000 RPS.
Для бекенда нам потребуется:
- ```106875/5000RPS= 21.3 машины```, возьмем с запасом 22
Хранилище:
- ```123,3 Тб/4=31 машина```     
Так что нам потребуется 31 машина под хранилища, 22 под микросервисы на бэкенде и 5 для фронтенда.

## 8. **Выбор хостинга / облачного провайдера и расположения серверов**
Мы будем использловать свои дата центры, так как цены на облачные решения слишком велики для больших сервисов. Клиенты обращаются к нам в основном с территории Европы и США (для китайского и азиатского рынка создаются отдельные продукты, такие как daodao.com) расположим один дата центр в США(Нью-Йорк), а другой в Европе(Франфуркт), по 23 машины в каждом. 

## 9. **Схема балансировки нагрузки (входящего трафика и внутрипроектного, терминация SSL)**
Будем использовать nginx для балансировки нагрузки с использованием схемы L7. Это позволит равномерно распределить нагрузку и решит проблемы медленных клиентов. Также nginx имеет внутренние инструменты для настройки SSL терминации.

## 10. **Обеспечение отказоустойчивости**
Отказоустойчивость обеспечивается несколкими компонентами:
1) Микросервисная архитектура с поднятыми несколькими экземплярами каждого сервиса
2) Несколько балансировщиков нагрузки, позволяющих в случае падения одного из них, перекинуть запросы на другие.
3) Использоваине технологии RAID 10 для хранения данных пользователей и медиа информации, допустимое количество вышедших из строя дисков от 1 до N/2 дисков. Информация не потеряется, если выйдут из строя диски в пределах разных зеркал.
4) Мониторинг метрик, с автоматическим оповещением сотрудников в случае нештатных ситуаций.
